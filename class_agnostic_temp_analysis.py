# -*- coding: utf-8 -*-
"""Copia di Class-AgnosticEntropyAnalysis3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ncRkP7dEQ0YXYKm0lqiXQJoifZA4XyiE
"""

alt_prompts = [
    "a tool used for building",
    "a piece of sports equipment",
    "an everyday household item",
    "a structure made of wood",
    "a machine with moving parts",

    "a plant growing in the wild",
    "a rocky landscape element",
    "a body of fresh water",
    "an animal living in the forest",
    "a scene from a farm",

    "a flying vertebrate",
    "a cold-blooded animal",
    "a sea creature with fins",
    "a mammal with hooves",
    "an animal commonly kept as a pet",
    "a bird that swims",
    "a predator in the wild",
    "an insect with wings",
    "a colorful creature",


    "a ground vehicle with tires",
    "a personal mode of transport",
    "a machine used for flying",
    "a watercraft used for travel",

    "an electronic device",
    "a colorful plastic object",
    "a synthetic object with buttons",
    "a shiny metallic gadget",

    "an overhead view of something",
    "a profile view of an item",
    "a detailed macro photograph",
    "a blurry distant figure",


    "a thing often found in nature"
]

!pip install -q transformers datasets torchvision matplotlib scikit-learn

import torch
from transformers import CLIPProcessor, CLIPModel

device = "cuda" if torch.cuda.is_available() else "cpu"
print("device", device)

model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32").to(device)
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

# Tokenize and encode the prompts
text_inputs = processor(alt_prompts, return_tensors = "pt", padding = True,
                             truncation = True).to(device)

with torch.no_grad():
  text_features = model.get_text_features(**text_inputs)

# Normalize text features
text_features = text_features / text_features.norm(dim = 1, keepdim = True)

print(f"Encoded {len(alt_prompts)} prompts into embeddings of shape: {text_features.shape}")

from torchvision.datasets import CIFAR100
from torch.utils.data import DataLoader
import numpy as np
from tqdm.notebook import tqdm

!wget https://data.brainchip.com/dataset-mirror/cifar100/cifar-100-python.tar.gz -O cifar-100-python.tar.gz

!mkdir -p ./data

!tar -xvzf cifar-100-python.tar.gz -C ./data

from torchvision.datasets import CIFAR100
from torchvision import transforms


train_dataset = CIFAR100(root="./data", train=True, download=False)
test_dataset = CIFAR100(root="./data", train=False, download=False)

!pip install scikit-learn -q

import torch.nn.functional as F
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import numpy as np
from tqdm import tqdm


def collate_fn(batch):
    images = [item[0] for item in batch]
    labels = [item[1] for item in batch]
    inputs = processor(images=images, return_tensors="pt", padding=True).to(device)
    return inputs, torch.tensor(labels, dtype=torch.long)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)

def extract_logit_features(data_loader, text_features, temperature):
    image_features_list = []
    labels_list = []
    entropies = []
    top1_confidences = []

    for inputs, labels in tqdm(data_loader):
        with torch.no_grad():
            image_features = model.get_image_features(**inputs)
            image_features = image_features / image_features.norm(dim=1, keepdim=True)
            logits = (image_features @ text_features.T) / temperature

            probs = F.softmax(logits, dim=1)
            entropy = -torch.sum(probs * torch.log(probs + 1e-9), dim=1)
            entropies.append(entropy.cpu().numpy())

            top1_conf = probs.max(dim=1).values
            top1_confidences.append(top1_conf.cpu().numpy())

        image_features_list.append(logits.cpu().numpy())
        labels_list.append(labels.cpu().numpy())

    features = np.concatenate(image_features_list, axis=0)
    labels = np.concatenate(labels_list, axis=0)
    all_entropy = np.concatenate(entropies)
    all_top1_conf = np.concatenate(top1_confidences)

    return features, labels, all_entropy.mean(), all_top1_conf.mean()


temps = [0.5, 0.07, 0.05, 0.03, 0.02]
accuracies = []
entropies = []
confidences = []


for temp in temps:
    print(f"\nTesting with Temperature = {temp}")
    train_features, train_labels, train_entropy, train_conf = extract_logit_features(train_loader, text_features, temp)
    test_features, test_labels, test_entropy, test_conf = extract_logit_features(test_loader, text_features, temp)

    svm_clf = SVC(kernel='linear', C=1.0, random_state=42)
    svm_clf.fit(train_features, train_labels)
    test_preds = svm_clf.predict(test_features)
    acc = accuracy_score(test_labels, test_preds)

    print(f"Mean Entropy: {test_entropy:.4f} | Top-1 Confidence: {test_conf:.4f} | SVM Accuracy: {acc*100:.2f}%")


    accuracies.append(acc * 100)
    entropies.append(test_entropy)
    confidences.append(test_conf)

# Plot accuracy vs temperature
plt.figure(figsize=(8, 5))
plt.plot(temps, accuracies, marker='o', color='blue', label='Accuracy')
plt.xlabel("Temperature")
plt.ylabel("SVM Accuracy (%)")
plt.title("Accuracy vs Temperature")
plt.grid(True)
plt.legend()
plt.gca().invert_xaxis()
plt.tight_layout()
plt.show()